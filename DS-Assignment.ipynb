{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a716389a-e46c-4e15-b473-b40d7c79a1d3",
   "metadata": {},
   "source": [
    "##### Instructions\n",
    "- Keep the original structure, you may add additional code cells and/or mark-down cells for clarity, legibility and/or structure.\n",
    "- Add the required descriptions, explanations, justifications to the mark-down cells. You can find more mark-down tips & tricks online, for example [here](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html) and [here](https://www.ibm.com/docs/en/watson-studio-local/1.2.3?topic=notebooks-markdown-jupyter-cheatsheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b017957-b9de-4e04-8dad-d90e9bea213d",
   "metadata": {},
   "source": [
    "# EXAM03: Data Science Group Assignment - Iteration 1\n",
    "\n",
    "**Group name:** Timo & Jakub\n",
    "\n",
    "**Student names & numbers:**\n",
    "* Timo Storny - 00099699\n",
    "* Jakub Holik - [Student no.]\n",
    "* [Name 3] - [Student no.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735319e-ed1e-45a0-a976-2aff38fd4180",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0. Iteration setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f6f7d-068b-4554-8d4e-c088a8909db4",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc780e8c-cba7-450e-b5d5-6b2445a11681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: import the necessary libraries for this iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4cb004-acbc-4566-abd1-fc4d5345d47d",
   "metadata": {},
   "source": [
    "**Load dataset(s)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cffc45c-3fdb-4e7c-9e6a-cb6983a5d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: import the necessary dataset(s) for this iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea875bf-f228-4c0f-b353-206a163ec75c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Business Understanding\n",
    "*Rubric: LO 6.4D (Reflection on Process)*\n",
    "\n",
    "**Situation description**\n",
    "\n",
    "Nebula Brokerage currently prices spaceships using \"gut feeling\" and rough averages. This is risky, because the inventory prices are highly spread and include extreme outliers, which makes the average inaccurate. Also with this much price variation, it becomes more diffcult to consistently price incoming ships and it may lead to underpricing rare ships (lost profit) or overpricing common ships (low sales and sitting inventory).\n",
    "\n",
    "**Business objective(s)**\n",
    "\n",
    "Nebula Brokerage needs a data-driven baseline price that can be used as a standard reference for incoming ships, before building complex AI models. This baseline should:\n",
    " - Provide a consistent starting point for pricing decisions.\n",
    " - Provide a statistically derived benchmark that will minimize average error\n",
    "\n",
    "**Data mining goal(s)**\n",
    "\n",
    "We are going to use naive regression models (mean and median) to determine the best baseline price without knowing anything about the incoming ships. This should minimize the Mean Absolute Error (MAE) and Root Mean Squared Error (EMSE). \n",
    "\n",
    "**Success criteria**\n",
    "\n",
    "We successfully deliver a single baseline reference price for incoming ships that:\n",
    "- Is derived from the dataset\n",
    "- Minimizes prediction error without any incoming ship details:\n",
    "  - Use median as the baseline if optimizing MAE\n",
    "  - Use mean as the basline if optimizing RMSE\n",
    "- Includes benchmark performance numbers (MAE and RMSE), so future models can be compared against it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd5f790-54b1-4ee4-838f-2e813e3513be",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Understanding\n",
    "*Rubric: LO 7.3Q (Visuals) & LO 6.4C (Process)*\n",
    "\n",
    "**Data exploration**\n",
    "\n",
    "*Include summary statistics and descriptions of data types below. Describe your findings.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5251d-5aee-4b9f-8564-193785930d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: Show basic statistics and information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96797443-654e-4a65-a9fa-84a8a3fbf741",
   "metadata": {},
   "source": [
    "**Visualizations and patterns**\n",
    "\n",
    "*Discover patterns in the data by creating visualizations. Create at least a histogram of Galactic_Credits. Describe your observations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb56161c-753c-412c-b95f-ce9b8bf1dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: Generate visualizations (e.g., scatter plots, histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65918398-cc3a-4986-8530-8e32b69681cc",
   "metadata": {},
   "source": [
    "**Data insights and data quality**\n",
    "* **Insights:** What are the key trends? What does the distribution look like? What does that mean? \n",
    "* **Quality issues:** Document missing values, duplicates, outliers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f69990a-91c8-48ff-bf04-8658c6e2e6a6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Data Preparation\n",
    "*Rubric: LO 6.4C (Data Science Steps)*\n",
    "\n",
    "**Cleaning and preprocessing**\n",
    "*Describe and justify steps taken (e.g., imputation, handling outliers, fixing other errors).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f186c7a-10d1-4808-9818-e14ab7d116b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: Data cleaning and preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9974d45f-a56b-4a13-b8e9-daf8ef5029bf",
   "metadata": {},
   "source": [
    "**Adjusting dataset (optional)**\n",
    "*If you adjusted the dataset for modeling in additional ways, describe that here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9b7120d-8bad-4b78-84bf-d62c7d503aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL CODE CELL: Additional preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a9873-64fa-4b76-b891-8ffd2e968728",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Modeling\n",
    "*Rubric: LO 6.4C (Data Science Steps)*\n",
    "\n",
    "**Model setup**\n",
    "*Describe and justify the creation of your simple benchmark model to predict Galactic_Credits*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd902930-dbad-4e7a-854b-2b6a31774d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: Model training and setup code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e31d2ad-37e3-462e-87c0-feed5d13b6a7",
   "metadata": {},
   "source": [
    "**Testing and performance**\n",
    "*Describe how you tested the model and interpret the metrics. Make sure to present the metrics in a clear overview.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05fc70ff-ca1d-4cfd-b9ef-e65c86a7a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: Model evaluation code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b7202-d834-4571-8ce0-b7c8944058fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Evaluation\n",
    "*Rubric: LO 6.4C (Results vs. Objectives)*\n",
    "\n",
    "**Assessment against succes criteria** \n",
    "*What is the difference between the metrics? What does this mean? Did you meet the goals set in the Business Understanding?*\n",
    "\n",
    "**Key findings and limitations**\n",
    "*What did you learn? What are the limitations of this current model?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c53c2-ca1c-4182-ab8a-1bc1ba693eaf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6 Personal Contribution\n",
    "*Rubric: LO 7.3P (Equal Contribution)*\n",
    "\n",
    "| Student name | Contribution | Personal lessons learned |\n",
    "| :--- | :--- | :--- |\n",
    "| Student name 1 | *Contribution description* | *Personal lessons learned this iteration* |\n",
    "| Student name 2 | *Contribution description* | *Personal lessons learned this iteration* |\n",
    "| Student name 3 | *Contribution description* | *Personal lessons learned this iteration* |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
